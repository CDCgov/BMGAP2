name: CI

on:
    push:
        branches:
            - main
            - lskatz-qsub-array
    pull_request:
        branches:
            - main

env:
    # increment this number if you want to rebuild the cache
    cache-build-number: 3
    cache-pixi-path: ${{ github.workspace }}/.pixi
    cache-hg-path: ${{ github.workspace }}/analysis_scripts/hg38

jobs:
    build:
        runs-on: ubuntu-22.04
        strategy:
            matrix:
                SRR: [SRR8034137]
        steps:
            - name: Checkout code
              uses: actions/checkout@v2
            - name: install pixi and update BMGAP environment
              run: |
                curl -fsSL https://pixi.sh/install.sh | sh
                echo "$HOME/.pixi/bin" >> $GITHUB_PATH
                echo "$GITHUB_WORKSPACE/analysis_scripts" >> $GITHUB_PATH
                sudo apt-get install -y tree
            - name: cache-pixi-env
              id: cache-pixi-env
              uses: actions/cache@v4
              with:
                path: |
                  #$GITHUB_WORKSPACE/.pixi
                  ${{ github.workspace }}/pixi.toml
                  ${{ github.workspace }}/.pixi
                key: ${{ runner.os }}-pixi-${{ hashFiles('BMGAP_Conda_all.yml') }}-${{ env.cache-build-number }}
            
            - name: Set up pixi env
              if: steps.cache-pixi-env.outputs.cache-hit != 'true'
              run: |
                  pixi init --import BMGAP_Conda_all.yml
                  pixi add awscli sra-tools seqtk
                  pixi --verbose install
            
            - name: cache-SRR
              id: cache-SRR
              uses: actions/cache@v4
              with:
                path: ${{ github.workspace }}/test.in/${{ matrix.SRR }}
                key: ${{ runner.os }}-SRR-${{ matrix.SRR }}-${{ hashFiles('BMGAP_Conda_all.yml') }}-${{ env.cache-build-number }}
            - name: download test data
              if: steps.cache-SRR.outputs.cache-hit != 'true'
              run: |
                  mkdir -pv test.in/${{ matrix.SRR }}
                  pixi run fasterq-dump ${{ matrix.SRR }} --threads 1 --outdir test.in/${{ matrix.SRR }} --split-files --skip-technical
                  # downsample to 120x coverage
                  pixi run seqtk sample -s11 test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_1.fastq 55200 | \
                    gzip -c > test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_R1.fastq.gz
                  pixi run seqtk sample -s11 test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_2.fastq 55200 | \
                    gzip -c > test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_R2.fastq.gz
                  rm -v test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_1.fastq
                  rm -v test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_2.fastq
          
            - name: cache-human-genome
              id: cache-human-genome
              uses: actions/cache@v4
              with:
                path: |
                  ${{ env.cache-hg-path }}
                key: ${{ runner.os }}-hg38-${{ hashFiles('BMGAP_Conda_all.yml') }}-${{ matrix.SRR }}-${{ env.cache-build-number }}
            
            - name: download human genome
              if: steps.cache-human-genome.outputs.cache-hit != 'true'
              run: |
                  aws s3 --no-sign-request --region eu-west-1 sync s3://ngi-igenomes/igenomes/Homo_sapiens/NCBI/GRCh38/Sequence/Bowtie2Index/ ${{ env.cache-hg-path }}
                  #gzip -9v ${{ env.cache-hg-path }}/genome.fa
                  # index files are here and so just remove the genome fasta when ready
                  rm -v ${{ env.cache-hg-path }}/genome.fa
            - name: view environment
              run: |
                tree $GITHUB_WORKSPACE
                echo "======="
                tree ${{ env.cache-hg-path}}
            
            - name: cache-MLST-and-Mash
              id: cache-mlst-and-mash
              uses: actions/cache@v4
              with:
                path: |
                  ${{ github.workspace }}/analysis_scripts/PMGA/pubmlst_dbs_all
                  ${{ github.workspace }}/analysis_scripts/SpeciesDB/lib/RefSeqSketchesDefaults.msh
                  ${{ github.workspace }}/analysis_scripts/PMGA/lib/RefSeqSketchesDefaults.msh
                key: ${{ runner.os }}-MlstAndMash-${{ matrix.SRR }}-${{ hashFiles('BMGAP_Conda_all.yml') }}-${{ env.cache-build-number }}
            
            - name: build MLSTDB
              if: steps.cache-mlst-and-mash.outputs.cache-hit != 'true'
              run: |
                cd ${{ github.workspace }}/analysis_scripts/PMGA && \
                  pixi run python build_pubmlst_dbs.py -o pubmlst_dbs_all
            - name: build MashDB
              if: steps.cache-mlst-and-mash.outputs.cache-hit != 'true'
              run: |
                wget -O- http://gembox.cbcb.umd.edu/mash/RefSeqSketchesDefaults.msh.gz | gunzip -c \
                  > ${{ github.workspace }}/analysis_scripts/SpeciesDB/lib/RefSeqSketchesDefaults.msh 
                ln -v ${{ github.workspace }}/analysis_scripts/SpeciesDB/lib/RefSeqSketchesDefaults.msh ${{ github.workspace }}/analysis_scripts/PMGA/lib/RefSeqSketchesDefaults.msh
            - name: uncompress locus extractor db
              run: |
                gunzip -v ${{ github.workspace }}/analysis_scripts/locusextractor/settings_antibiotics/lookupTables/Isolate2MLST2Species.txt.gz

            # Cache the first test just because it takes so long.
            # The cache key depends on the hash of Alignment.sh to ensure that
            # it refreshes the cache if the script changes at all.
            - name: cache-alignment
              id: cache-alignment
              uses: actions/cache@v4
              with:
                path: |
                  ${{ github.workspace }}/out/${{ matrix.SRR }}_SPAdes
                  ${{ github.workspace }}/${{ matrix.SRR }}_R1_dedup*.fastq.gz
                key: ${{ runner.os }}-alignment-${{ matrix.SRR }}-${{ hashFiles('BMGAP_Conda_all.yml') }}-${{ hashFiles('analysis_scripts/Alignment.sh') }}-${{ env.cache-build-number }}
            - name: test-alignment
              if: steps.cache-alignment.outputs.cache-hit != 'true'
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                mkdir -v $GITHUB_WORKSPACE/out
                pixi run bash $ANALYSIS_SCRIPTS/Alignment.sh test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_R1.fastq.gz test.in/${{ matrix.SRR }}/${{ matrix.SRR }}_R2.fastq.gz $GITHUB_WORKSPACE/out ${{ matrix.SRR }}
                # Remove the fastq files to save space. It was 500M in my hands.
                find $GITHUB_WORKSPACE/out/${{ matrix.SRR }}_SPAdes -name "*.fastq.gz" -delete
            
            - name: test-cleanup
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/cleanupSingle.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }}
            - name: test-bmscan
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/BMScan.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }}
            
            # PMGA took 45m to run in GitHub Actions, so we cache it, based on hashsum of input assembly file
            - name: cache-pmga
              id: cache-pmga
              uses: actions/cache@v4
              with:
                path: |
                  ${{ github.workspace }}/out/characterization/PMGA
                key: ${{ runner.os }}-PMGA-${{ hashFiles('analysis_scripts/PMGA.sh') }}-${{ hashFiles('/home/runner/work/BMGAP2/BMGAP2/out/${{ matrix.SRR }}_SPAdes/scaffolds.fasta') }}-${{ env.cache-build-number }}
                #key: ${{ runner.os }}-PMGA-${{ hashFiles('analysis_scripts/PMGA.sh') }}--${{ env.cache-build-number }}

            - name: test-pmga
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              if: steps.cache-pmga.outputs.cache-hit != 'true'
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/PMGA.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }}

            - name: cache-locusextractor
              id: cache-locusextractor
              uses: actions/cache@v4
              env:
                cache-check-fasta-path: /home/runner/work/BMGAP2/BMGAP2/out/${{ matrix.SRR }}_SPAdes/scaffolds.fasta
              with:
                path: |
                  ${{ github.workspace }}/out/characterization/LE_2.0.2_${{ matrix.SRR }}_000000
                key: ${{ runner.os }}-LE-${{ matrix.SRR }}-${{ hashFiles('analysis_scripts/LocusExtractor.sh') }}-${{ hashFiles('env.cache-check-fasta-path') }}-${{ env.cache-build-number }}

            - name: test-locusextractor
              if: steps.cache-locusextractor.outputs.cache-hit != 'true'
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/LocusExtractor.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }} 2>&1
                # Make it easier to cache and retrieve results by lopping off the date
                echo
                #tree $GITHUB_WORKSPACE
                find $GITHUB_WORKSPACE -type d -name "LE*"
                # should only be one folder and so this asterisk should be safe
                mv -v $GITHUB_WORKSPACE/out/characterization/LE_*_${{ matrix.SRR }}_* \
                  $GITHUB_WORKSPACE/out/characterization/LE_2.0.2_${{ matrix.SRR }}_000000
            - name: test-amr
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/AMR.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }}
            - name: test-prepareToShare
              env:
                NSLOTS: 2
                ANALYSIS_SCRIPTS: ${{ github.workspace }}/analysis_scripts
              run: |
                pixi run bash $ANALYSIS_SCRIPTS/PrepareToShare.sh $GITHUB_WORKSPACE/out ${{ matrix.SRR }}
                ls -lh $GITHUB_WORKSPACE/out
            - name: check file structure
              run: |
                echo "Checking output"
                tree $GITHUB_WORKSPACE/out
                echo
                ls -lhRA $GITHUB_WORKSPACE/out
            - name: check results
              run: |
                pixi add jq
                pixi install
                # stash json result files into an easy folder
                mkdir json
                #find $GITHUB_WORKSPACE/out -name "*.json" -exec ln -sv
                # use jq to extract the species from "SRR8034137_cleaned.fasta": {"mash_results": {"species": "Neisseria meningitidis",
                #obs_species=$(pixi run jq '.["SRR8034137_cleaned.fasta"].mash_results.species' $GITHUB_WORKSPACE/out/${{ matrix.SRR }}/characterization/BMScan/species_analysis*.json)
                #obs_adk=$(pixi run jq '.Nm_MLST_adk."0"' out/characterization/LE_*/molecular_data_${{ matrix.SRR }}.json)
                # Make actual assertions so that it exits with 0 or not
                # TODO when there are more test data: put this logic into a script
                #echo "obs_species: $obs_species"
                #echo "obs_adk: $obs_adk"
                #[[ "$obs_species" == "Neisseria meningitidis" ]]
                #[[ "$obs_adk" == "10" ]]
